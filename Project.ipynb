{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55bfac11-6d5c-4c9c-9b7c-485bd3d3c467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from scikit-learn) (3.4.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.3.0-cp39-cp39-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.13.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch) (4.9.0)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch) (3.1.3)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.3.0 (from torch)\n",
      "  Downloading triton-2.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from jinja2->torch) (2.1.4)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.3.0-cp39-cp39-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m927.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m963.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m733.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.13.4-py3-none-any.whl (11 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "Successfully installed filelock-3.13.4 fsspec-2024.3.1 mpmath-1.3.0 networkx-3.2.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sympy-1.12 torch-2.3.0 triton-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd6e3d4d-b94b-476a-8fe9-9a1d05cfeb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging completed.\n"
     ]
    }
   ],
   "source": [
    "# Define the directories containing the positive and negative files\n",
    "negative_dir = '/users/hutruon/Assignment-1-CS490/Data/NegativeFile'\n",
    "positive_dir = '/users/hutruon/Assignment-1-CS490/Data/PositiveFile'\n",
    "\n",
    "# Define the output file path\n",
    "output_file_path = '/users/hutruon/Assignment-1-CS490/Data/merged_data.txt'\n",
    "\n",
    "# List of negative and positive files\n",
    "negative_files = os.listdir(negative_dir)\n",
    "positive_files = os.listdir(positive_dir)\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"Read the contents of a file and return them as a list.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.readlines()\n",
    "\n",
    "def merge_files(pos_file_path, neg_file_path, output_file, label_pos='1', label_neg='0'):\n",
    "    \"\"\"Append lines from positive and negative files to the output file with labels.\"\"\"\n",
    "    pos_lines = read_file(pos_file_path)\n",
    "    neg_lines = read_file(neg_file_path)\n",
    "    \n",
    "    with open(output_file, 'a') as file:\n",
    "        for line in pos_lines:\n",
    "            file.write(f\"{label_pos} {line}\")\n",
    "        for line in neg_lines:\n",
    "            file.write(f\"{label_neg} {line}\")\n",
    "\n",
    "# Ensure the output file is empty or does not exist before starting\n",
    "if os.path.exists(output_file_path):\n",
    "    os.remove(output_file_path)\n",
    "\n",
    "# Merge files with matching identifiers\n",
    "for pos_file in positive_files:\n",
    "    # Construct the corresponding negative file name\n",
    "    neg_file = pos_file.replace(\"_100nt.txt\", \"_negative_100nt.txt\")\n",
    "    if neg_file in negative_files:\n",
    "        merge_files(os.path.join(positive_dir, pos_file), os.path.join(negative_dir, neg_file), output_file_path)\n",
    "    else:\n",
    "        print(f\"Matching negative file not found for {pos_file}\")\n",
    "\n",
    "print(\"Merging completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cb5462d-9fcc-44ce-a5dd-17afa116d6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training (1300592 lines), testing (346824 lines), and validation (86707 lines).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Path to the merged data file\n",
    "merged_file_path = '/users/hutruon/Assignment-1-CS490/Data/merged_data.txt'\n",
    "\n",
    "# Paths for the output files\n",
    "train_file_path = '/users/hutruon/Assignment-1-CS490/Data/train_data.txt'\n",
    "test_file_path = '/users/hutruon/Assignment-1-CS490/Data/test_data.txt'\n",
    "validation_file_path = '/users/hutruon/Assignment-1-CS490/Data/validation_data.txt'\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"Read the contents of a file and return them as a list.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    return lines\n",
    "\n",
    "def write_file(file_path, lines):\n",
    "    \"\"\"Write the given lines to a file.\"\"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "# Read the merged data\n",
    "data_lines = read_file(merged_file_path)\n",
    "\n",
    "# Shuffle the data to ensure randomness\n",
    "# It's important for machine learning models to be trained on data that's in a random order.\n",
    "import random\n",
    "random.shuffle(data_lines)\n",
    "\n",
    "# Split data into training (75%), and a temporary set (25%)\n",
    "train_lines, temp_lines = train_test_split(data_lines, test_size=0.25, random_state=42)\n",
    "\n",
    "# Split the temporary set into testing (20% of total) and validation (5% of total)\n",
    "# Since the temporary set is 25% of the total, we'll allocate 80% of it to testing and 20% to validation\n",
    "# which corresponds to 20% and 5% of the total data, respectively.\n",
    "test_lines, validation_lines = train_test_split(temp_lines, test_size=0.2, random_state=42)  # 0.2 * 0.25 = 0.05\n",
    "\n",
    "# Write the split data to their respective files\n",
    "write_file(train_file_path, train_lines)\n",
    "write_file(test_file_path, test_lines)\n",
    "write_file(validation_file_path, validation_lines)\n",
    "\n",
    "print(f\"Data split into training ({len(train_lines)} lines), testing ({len(test_lines)} lines), and validation ({len(validation_lines)} lines).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edefa01c-f2f6-4f97-b0a3-8ff300dfa35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot_encoder(sequence):\n",
    "    \"\"\"Converts a DNA sequence to a one-hot encoded numpy array.\"\"\"\n",
    "    mapping = {'A': [1, 0, 0, 0], 'C': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'T': [0, 0, 0, 1]}\n",
    "    one_hot_encoded = [mapping.get(nucleotide, [0, 0, 0, 0]) for nucleotide in sequence]\n",
    "    return np.array(one_hot_encoded)\n",
    "\n",
    "def read_and_encode(file_path):\n",
    "    labels = []\n",
    "    encoded_sequences = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            label, sequence = line.strip().split(maxsplit=1)\n",
    "            labels.append(int(label))\n",
    "            encoded_sequences.append(one_hot_encoder(sequence))\n",
    "    return np.array(labels), np.array(encoded_sequences)\n",
    "\n",
    "# Set the path to your test_data.txt file\n",
    "file_path = '/users/hutruon/Assignment-1-CS490/Data/test_data.txt'\n",
    "\n",
    "# Read and encode the sequences\n",
    "labels, encoded_sequences = read_and_encode(file_path)\n",
    "\n",
    "# Now, labels and encoded_sequences contain the data you need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98eab7c3-82c0-4328-8ce6-7aaa4072f14d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 1., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.],\n",
      "         [0., 0., 1., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [1., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [1., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 1.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]]) tensor([1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Step 3: One-hot encoding function\n",
    "def one_hot_encoder(sequence):\n",
    "    mapping = {'A': [1, 0, 0, 0], 'C': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'T': [0, 0, 0, 1]}\n",
    "    return np.array([mapping.get(nucleotide, [0, 0, 0, 0]) for nucleotide in sequence])\n",
    "\n",
    "# Function to read and encode data from a file\n",
    "def read_data_and_encode(file_path):\n",
    "    labels = []\n",
    "    encoded_data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            label, sequence = line.strip().split(' ', 1)\n",
    "            labels.append(int(label))\n",
    "            encoded_data.append(one_hot_encoder(sequence))\n",
    "    return np.array(labels), np.array(encoded_data)\n",
    "\n",
    "# Custom Dataset class\n",
    "class DNADataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.data = torch.stack([torch.tensor(s, dtype=torch.float32) for s in sequences])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Main program\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 4: Read and encode data\n",
    "    labels, encoded_data = read_data_and_encode('test_data.txt')\n",
    "    \n",
    "    # Step 8: Instantiate the dataset\n",
    "    test_dataset = DNADataset(encoded_data, labels)\n",
    "    \n",
    "    # Step 9: Create a DataLoader\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=512, shuffle=True)\n",
    "    \n",
    "    # Step 10: Iterate and print one batch\n",
    "    for data, label in test_dataloader:\n",
    "        print(data, label)\n",
    "        break  # Only print the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26f4aea4-78da-4c51-a031-99c9687383fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.18.0-cp39-cp39-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.3.0 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torchvision) (2.3.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading pillow-10.3.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: filelock in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from torch==2.3.0->torchvision) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from jinja2->torch==2.3.0->torchvision) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /users/hutruon/miniconda3/envs/env/lib/python3.9/site-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n",
      "Downloading torchvision-0.18.0-cp39-cp39-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.3.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pillow, torchvision\n",
      "Successfully installed pillow-10.3.0 torchvision-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0668baab-577d-40b8-acee-292ecc093043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside train\n",
      "\n",
      "Test set: Average loss: 0.6000, Accuracy: 229191/346824 (66%)\n",
      "\n",
      "==============================\n",
      "inside train\n",
      "\n",
      "Test set: Average loss: 0.5847, Accuracy: 232956/346824 (67%)\n",
      "\n",
      "==============================\n",
      "inside train\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv1d(4, 96, 11, stride=4, padding=5)  # Add padding\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Layer 2\n",
    "        self.conv2 = nn.Conv1d(96, 96, 1, padding=1)  # Add padding\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Layer 3\n",
    "        self.conv3 = nn.Conv1d(96, 96, 1, padding=1)  # Add padding\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool1d(3, stride=2)\n",
    "        self.drop3 = nn.Dropout(0.5)\n",
    "\n",
    "        # Layer 4\n",
    "        self.conv4 = nn.Conv1d(96, 192, 11, stride=4, padding=5)  # Add padding\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        # Layer 5\n",
    "        self.conv5 = nn.Conv1d(192, 192, 1, padding=1)  # Add padding\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        # Layer 6\n",
    "        self.conv6 = nn.Conv1d(192, 192, 1, padding=1)  # Add padding\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.pool6 = nn.MaxPool1d(3, stride=2)\n",
    "        self.drop6 = nn.Dropout(0.5)\n",
    "\n",
    "        # Layer 7\n",
    "        self.conv7 = nn.Conv1d(192, 384, 3, stride=1, padding=1)  # Add padding\n",
    "        self.relu7 = nn.ReLU()\n",
    "\n",
    "        # Layer 8\n",
    "        self.conv8 = nn.Conv1d(384, 384, 1, padding=1)  # Add padding\n",
    "        self.relu8 = nn.ReLU()\n",
    "\n",
    "        # Layer 9\n",
    "        self.conv9 = nn.Conv1d(384, 384, 1, padding=1)  # Add padding\n",
    "        self.relu9 = nn.ReLU()\n",
    "        self.drop9 = nn.Dropout(0.5)\n",
    "\n",
    "        # Layer 10\n",
    "        self.conv10 = nn.Conv1d(384, 20, 3, stride=1, padding=1)  # Add padding\n",
    "        self.relu10 = nn.ReLU()\n",
    "\n",
    "        # Layer 11\n",
    "        self.conv11 = nn.Conv1d(20, 20, 1, padding=1)  # Add padding\n",
    "        self.relu11 = nn.ReLU()\n",
    "\n",
    "        # Layer 12\n",
    "        self.conv12 = nn.Conv1d(20, 20, 1, padding=1)  # Add padding\n",
    "        self.relu12 = nn.ReLU()\n",
    "        self.adapool = nn.AdaptiveAvgPool1d((1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.drop3(self.pool3(self.relu3(self.conv3(x))))\n",
    "        x = self.relu4(self.conv4(x))\n",
    "        x = self.relu5(self.conv5(x))\n",
    "        x = self.drop6(self.pool6(self.relu6(self.conv6(x))))\n",
    "        x = self.relu7(self.conv7(x))\n",
    "        x = self.relu8(self.conv8(x))\n",
    "        x = self.drop9(self.relu9(self.conv9(x)))\n",
    "        x = self.relu10(self.conv10(x))\n",
    "        x = self.relu11(self.conv11(x))\n",
    "        x = self.adapool(self.relu12(self.conv12(x)))\n",
    "        x = torch.flatten(x, 1)  # Flatten for potential further layers or a classifier\n",
    "        return x\n",
    "\n",
    "\n",
    "# Step 3: One-hot encoding function\n",
    "def one_hot_encoder(sequence):\n",
    "    mapping = {'A': [1, 0, 0, 0], 'C': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'T': [0, 0, 0, 1]}\n",
    "    return np.array([mapping.get(nucleotide, [0, 0, 0, 0]) for nucleotide in sequence])\n",
    "\n",
    "# Function to read and encode data from a file\n",
    "def read_data_and_encode(file_path):\n",
    "    labels = []\n",
    "    encoded_data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            label, sequence = line.strip().split(' ', 1)\n",
    "            labels.append(int(label))\n",
    "            encoded_data.append(one_hot_encoder(sequence))\n",
    "    return np.array(labels), np.array(encoded_data)\n",
    "\n",
    "# Custom Dataset class\n",
    "class DNADataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.data = torch.stack([torch.tensor(s, dtype=torch.float32) for s in sequences])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        # Reshape data to have 4 channels\n",
    "        data = data.transpose(1, 0)\n",
    "        return data, self.labels[idx]\n",
    "\n",
    "# Main program\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 4: Read and encode data\n",
    "    labels, encoded_data = read_data_and_encode('test_data.txt')\n",
    "    \n",
    "    # Step 8: Instantiate the dataset\n",
    "    test_dataset = DNADataset(encoded_data, labels)\n",
    "    \n",
    "    # Step 9: Create a DataLoader\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    # Read and encode training data\n",
    "    train_labels, train_encoded_data = read_data_and_encode('train_data.txt')\n",
    "\n",
    "    # Instantiate the training dataset\n",
    "    train_dataset = DNADataset(train_encoded_data, train_labels)\n",
    "\n",
    "    # Create a DataLoader for the training data\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)  \n",
    "    \n",
    "\n",
    "# Instantiating the model and assigning an optimizer to the model and creating a loss function\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer=optim.Adam(params=model.parameters(),lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model,device,train_dataloader,optimizer,epochs):\n",
    "    print(\"inside train\")\n",
    "    model.train()\n",
    "    for batch_ids, (img, classes) in enumerate(train_dataloader):\n",
    "        classes=classes.type(torch.LongTensor)\n",
    "        img,classes=img.to(device),classes.to(device)\n",
    "        torch.autograd.set_detect_anomaly(True)     \n",
    "        optimizer.zero_grad()\n",
    "        output=model(img)\n",
    "        loss = loss_fn(output,classes)                \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if(batch_ids +1) % 2 == 0:\n",
    "        print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "            epochs, batch_ids* len(img), len(train_dataloader.dataset),\n",
    "            100.*batch_ids / len(train_dataloader),loss.item()))\n",
    "\n",
    "def test(model, device, test_dataloader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for img, classes in test_dataloader:\n",
    "            img, classes = img.to(device), classes.to(device)\n",
    "            output = model(img)\n",
    "            test_loss += F.cross_entropy(output, classes, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True) \n",
    "            correct += pred.eq(classes.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_dataloader.dataset),\n",
    "        100. * correct / len(test_dataloader.dataset)))\n",
    "    print('=' * 30)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    seed=42\n",
    "    EPOCHS=3\n",
    "    \n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        train(model,device,train_dataloader,optimizer,epoch)\n",
    "        test(model,device,test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd63f4-6e1f-4fd5-ba09-34cee16ff98c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env] *",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
